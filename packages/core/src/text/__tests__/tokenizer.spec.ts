import { Tokenizer } from '..'

describe('Tokenizer', () => {
  test('isBreakingSpace', () => {
    expect(Tokenizer.isBreakingSpace(' '.codePointAt(0)!)).toBe(true)
    expect(Tokenizer.isBreakingSpace('  '.codePointAt(0)!)).toBe(true)
    expect(Tokenizer.isBreakingSpace('A'.codePointAt(0)!)).toBe(false)
  })

  test('isNewline', () => {
    expect(Tokenizer.isNewline('\r')).toBe(true)
    expect(Tokenizer.isNewline('\n')).toBe(true)
  })

  test('isDigitOrLetter', () => {
    const digits = '0123456789'
    const letters = 'abcdefghijklmnopqrstuvwxyz'
    for (const char of digits.concat(letters).concat(letters.toUpperCase())) {
      expect(Tokenizer.isDigitOrLetter(char)).toBe(true)
    }
    expect(Tokenizer.isDigitOrLetter(' ')).toBe(false)
  })

  test('isPunctuationStart', () => {
    expect(Tokenizer.isPunctuationStart('â€œ')).toBe(true)
    expect(Tokenizer.isPunctuationStart(',')).toBe(false)
  })

  test('isPunctuationEnd', () => {
    expect(Tokenizer.isPunctuationEnd('â€œ')).toBe(false)
    expect(Tokenizer.isPunctuationEnd(',')).toBe(true)
  })

  test('isRegionalIndicator', () => {
    expect(Tokenizer.isRegionalIndicator('ğŸ‡¨'.codePointAt(0)!)).toBe(true)
  })

  describe('parse', () => {

    test('åŸºæœ¬çš„ä¸­è‹±æ··æ’å’Œåç½®æ ‡ç‚¹', () => {
      // const str = ' å½“å‰è¡Œé¦–æœ‰\u0009ç©ºæ ¼ã€‚\u2003at the\u2000\n   å½“å‰è¡Œé¦–æœ‰3ä¸ªç©ºæ ¼.\u3000è¡Œé¦–æ²¡æœ‰ç©ºæ ¼ã€‚ And no spaces at the end. check wrapping abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz. I \u2665 text. 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2     '
      // expect(Tokenizer.parse(str)).toEqual({})
      const str = 'ä½ å¥½ï¼Œä¸–ç•Œã€‚Hello, World.'
      expect(Tokenizer.parse(str)).toEqual(['ä½ ', 'å¥½ï¼Œ', 'ä¸–', 'ç•Œã€‚', 'Hello, ', 'World.'])
    })

    test('è¿ç»­çš„ç©ºç™½å’Œå‰ç½®ç©ºç™½', () => {
      const str = '   \u0009    leading spaces, \u2003      at the end.'
      expect(Tokenizer.parse(str)).toEqual(['   \u0009    ', 'leading ', 'spaces, \u2003      ', 'at ', 'the ', 'end.'])
    })

    test('é¢œæ–‡å­—æ··æ’', () => {
      const str = 'âœ‚ï¸     å¤åˆ¶ and ğŸ“‹ğŸ“‹ Paste'
      expect(Tokenizer.parse(str)).toEqual(['âœ‚ï¸     ', 'å¤', 'åˆ¶ ', 'and ', 'ğŸ“‹', 'ğŸ“‹ ', 'Paste'])
    })

    test('Variation Selectors', () => {
      const str = 'âœ‚ï¸ Copy'
      expect(Tokenizer.parse(str)).toEqual(['âœ‚ï¸ ', 'Copy'])
    })

    test('Emoji Modifiers', () => {
      const str = 'ğŸ‘¶ğŸ»ğŸ‘¦ğŸ»'
      expect(Tokenizer.parse(str)).toEqual(['ğŸ‘¶ğŸ»', 'ğŸ‘¦ğŸ»'])
    })

    test('Emoji flags', () => {
      const str = 'EnglishğŸ‡¬ğŸ‡§\næ±‰è¯­ğŸ‡¨ğŸ‡³\rã«ã»ã‚“ã”ğŸ‡¯ğŸ‡µ'
      expect(Tokenizer.parse(str)).toEqual([
        'English',
        'ğŸ‡¬ğŸ‡§',
        '\n',
        'æ±‰',
        'è¯­',
        'ğŸ‡¨ğŸ‡³',
        '\r',
        'ã«',
        'ã»',
        'ã‚“',
        'ã”',
        'ğŸ‡¯ğŸ‡µ',
      ])
    })
  })
})
